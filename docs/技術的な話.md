# 超大規模言語モデルを分散ネットワーク上で動かす技術
## はじめに
近年、超大規模言語モデル（LLM）は目覚ましい発展を遂げており、様々な分野で応用されている。
しかし、LLMは膨大な計算量とメモリを必要とするため、単一のノードで処理するには限界がある。
そこで、分散ネットワーク上でLLMを実行することで、処理能力を向上させ、より多くのユーザーに提供することが可能になる。

## 技術課題
分散ネットワーク上でLLMを実行するにあたって、以下の技術課題を克服する必要がある

- 分散処理: LLMを複数のノードに分割し、効率的に処理する必要がある
- 通信: ノード間で効率的に通信を行う必要がある
- 同期: ノード間でモデルの状態を同期させる必要がある
- プライバシー: 訓練データやモデルパラメータを保護する必要がある


## 提案手法
LLMを分散ネットワーク上で動かすために、以下の3つの手法を提案する。

### 手法1: 単純に計算資源を束ねて計算する
複数のノードの計算資源を束ねて、1つの大きな計算機として扱う手法。

利点:
- シンプルでわかりやすい

欠点:
- 計算効率が悪い
- 冗長性がない
- 通信量が多い
- 計算が非同期でない

### 手法2: モデルを分割して、各ノードで一部を処理する
モデルを複数のレイヤーに分割し、各レイヤーを異なるノードで処理する手法。

利点:
- 計算効率が向上する
- 冗長性がある

欠点:
- 計算が非同期でない
- モデル分割の難易度が高い

### 手法3: 小さなモデルを複数ノードで実行し、結果を統合する
各ノードで小さなLLMを実行し、その結果を統合することで、1つの大きなLLMの動作を模倣する手法([論文参照](https://arxiv.org/html/2402.05120v1))。

利点:
- 実装が簡単
- すぐに実現可能

欠点:
- 従来のLLMよりも性能が低い(いわゆるScaling Lowからは外れる)


## 技術の組み合わせ
LLMを分散ネットワーク上で動かす技術と、トークン発行やDAOなどの技術を組み合わせることで、以下のような新しいサービスやアプリケーションが実現可能になる。

- 分散型AIプラットフォーム: ユーザーが自分のデータやモデルを持ち寄り、協調的にLLMを訓練・利用できるプラットフォーム
- トークン型AIサービス: ユーザーがトークンを使ってLLMのサービスを利用できるサービス

## 今後の展望
LLMは、分散ネットワーク技術と組み合わせることで、さらに大きな可能性を秘めている。
今後、これらの技術が発展していくことで、
様々な分野で革新的なサービスやアプリケーションが生まれることが期待される。